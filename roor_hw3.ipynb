{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 27 апреля 2020, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 27 апреля, -4 балла после 08:30 4 мая, -6 баллов после 08:30 11 мая, -8 баллов после 08:30 18 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0220, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс DecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=5, criterion='gini'):\n",
    "        \"\"\"\n",
    "        criterion -- критерий расщепления. необходимо релизовать три:\n",
    "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
    "        max_depth -- максимальная глубина дерева\n",
    "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.num_class = -1\n",
    "        # Для последнего задания\n",
    "        self.feature_importances_ = None\n",
    "        self.criterion = criterion\n",
    "        # Структура, которая описывает дерево\n",
    "        # Представляет словарь, где для  node_id (айдишник узла дерева) храним\n",
    "        # (тип_узла, айдишник признака сплита, порог сплита) если тип NON_LEAF_TYPE\n",
    "        # (тип_узла, предсказание класса, вероятность класса) если тип LEAF_TYPE\n",
    "        # Подразумевается, что у каждого node_id в дереве слева \n",
    "        # узел с айди 2 * node_id + 1, а справа 2 * node_id + 2\n",
    "        self.tree = dict()\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "    \n",
    "    def __gini_F(self, l, r):\n",
    "        return 1 -(l / (l + r)) ** 2 - (r / (l + r)) ** 2\n",
    "\n",
    "    def __entropy_F(self, l, r):\n",
    "        def mylog2(x):\n",
    "            x[np.where(x < 1e-37)] = 1 # assume 0 * ln 0 = 0 (x=0 -> x=1 -> ln x = 0)\n",
    "            return np.log2(x)\n",
    "                \n",
    "        return -(l / (l + r)) * mylog2(l / (l + r))  - (r / (l + r)) * mylog2(r / (l + r))\n",
    "\n",
    "    def __misclass_F(self, l, r):\n",
    "        return 1 - np.maximum(l / (l + r), r / (l + r))\n",
    "    \n",
    "    def impurity(self, l, ls, r, rs):\n",
    "        if self.criterion == 'entropy':\n",
    "            F = self.__entropy_F\n",
    "        elif self.criterion == 'misclass':\n",
    "            F = self.__misclass_F\n",
    "        else:\n",
    "            F = self.__gini_F\n",
    "        \n",
    "        return F(l, r) - l / (l + r) * F(ls, l - ls) - r / (l + r) * F(rs, r - rs)\n",
    "    \n",
    "    def __find_threshold(self, x, y):\n",
    "        \"\"\"\n",
    "        Находим оптимальный признак и порог для сплита\n",
    "        Здесь используемые разные impurity в зависимости от self.criterion\n",
    "        \"\"\"\n",
    "        x = x.T\n",
    "        s_x = np.sort(x, axis = 1)\n",
    "        s_y = y[x.argsort(axis = 1)]\n",
    "        \n",
    "        s_y = (s_y == y[0]).astype(int)\n",
    "        _, occurs = np.bincount(s_y[0])\n",
    "        sumsl = np.cumsum(s_y, axis = 1)\n",
    "        sumsr = occurs - sumsl\n",
    "        len_ = s_y.shape[1]\n",
    "        \n",
    "        l = np.array(np.array(range(len_)) + np.zeros(s_y.shape[0]).reshape(-1, 1))\n",
    "        l[:, 0] += 1\n",
    "        r = len_ - l\n",
    "        impurities = self.impurity(l, sumsl, r, sumsr)\n",
    "        feature_id, threshold_idx = np.unravel_index(np.argmax(impurities), impurities.shape)\n",
    "        \n",
    "        return feature_id, s_x[feature_id, threshold_idx], impurities[feature_id, threshold_idx]\n",
    "    \n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \"\"\"\n",
    "        Делаем новый узел в дереве\n",
    "        Решаем, терминальный он или нет\n",
    "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
    "        И правый узел с  айди 2 * node_id + 2\n",
    "        \"\"\"\n",
    "        \n",
    "        if (depth == self.max_depth) or (y.size < self.min_samples_split):\n",
    "            y1, c = np.unique(y, return_counts = True)\n",
    "            prob = c / y.size\n",
    "            c = (-c).argsort()\n",
    "            y1 = y1[c]\n",
    "            self.tree[node_id] = (self.__class__.LEAF_TYPE, y1[0], prob)\n",
    "        else:\n",
    "            feature_id, threshold, crit_val = self.__find_threshold(x, y)\n",
    "            x_left, x_right, y_left, y_right = self.__div_samples(x, y, feature_id, threshold)\n",
    "            \n",
    "            if y_left.size > 0 and y_right.size > 0:\n",
    "                self.tree[node_id] = (self.__class__.NON_LEAF_TYPE, feature_id, threshold)\n",
    "                self.feature_importances[feature_id] += y.size * crit_val / x.shape[0]\n",
    "                self.__fit_node(x_left, y_left, 2 * node_id + 1, depth + 1)\n",
    "                self.__fit_node(x_right, y_right, 2 * node_id + 2, depth + 1)\n",
    "            else:\n",
    "                y1, c = np.unique(y, return_counts = True)\n",
    "                prob = c / y.size\n",
    "                c = (-c).argsort()\n",
    "                y1 = y1[c]\n",
    "                self.tree[node_id] = (self.__class__.LEAF_TYPE, y1[0], prob)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Рекурсивно строим дерево решений\n",
    "        Начинаем с корня node_id 0\n",
    "        \"\"\"\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Возвращает важность признаков\n",
    "        \"\"\"\n",
    "        return self.feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split = 2)\n",
    "clf = DecisionTreeClassifier(min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test),\n",
    "      accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.81 ms, sys: 673 µs, total: 4.48 ms\n",
      "Wall time: 4.26 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 ms, sys: 0 ns, total: 15.2 ms\n",
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Данные и описания колонок лежат тут\n",
    "https://cloud.mail.ru/public/8nHV/p6J7wY1y1/speed-dating-experiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.45e+02,  2.34e+02,  5.00e-02, ...,  0.00e+00,  0.00e+00,\n",
       "          0.00e+00],\n",
       "        [ 2.45e+02,  2.35e+02,  4.30e-01, ...,  0.00e+00,  0.00e+00,\n",
       "          0.00e+00],\n",
       "        [ 2.45e+02,  2.36e+02,  1.90e-01, ...,  0.00e+00,  0.00e+00,\n",
       "          0.00e+00],\n",
       "        ...,\n",
       "        [ 5.52e+02,  5.28e+02, -4.60e-01, ...,  0.00e+00,  0.00e+00,\n",
       "          0.00e+00],\n",
       "        [ 5.52e+02,  5.29e+02,  6.20e-01, ...,  0.00e+00,  0.00e+00,\n",
       "          0.00e+00],\n",
       "        [ 5.52e+02,  5.30e+02,  1.00e-02, ...,  0.00e+00,  0.00e+00,\n",
       "          0.00e+00]]), array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Speed Dating Data.csv', encoding='latin1')\n",
    "df = df.iloc[:, :97]\n",
    "\n",
    "df = df.drop(['id'], axis = 1)\n",
    "df = df.drop(['from'], axis = 1)\n",
    "df = df.drop(['idg'], axis = 1)\n",
    "df = df.drop(['condtn'], axis = 1)\n",
    "df = df.drop(['round'], axis = 1)\n",
    "df = df.drop(['wave'], axis = 1)\n",
    "df = df.drop(['position', 'positin1'], axis = 1)\n",
    "df = df.drop(['order'], axis = 1)\n",
    "df = df.drop(['partner'], axis = 1)\n",
    "df = df.drop(['age_o', 'race_o', 'pf_o_att', \n",
    "              'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha',\n",
    "              'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o',\n",
    "              'amb_o', 'shar_o', 'like_o', 'prob_o','met_o'], axis = 1)\n",
    "\n",
    "df = df.dropna(subset = ['age', 'imprelig', 'imprace'])\n",
    "df = df.drop(['field'], axis = 1)\n",
    "df = df.drop(['undergra'], axis = 1)\n",
    "\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'zipcode'] = df.loc[:, 'zipcode'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "\n",
    "df['mn_sat'] = df['mn_sat'].fillna(0.0)\n",
    "df['tuition'] = df['tuition'].fillna(0.0)\n",
    "df['income'] = df['income'].fillna(0.0)\n",
    "df['career_c'] = df['career_c'].fillna(0.0)\n",
    "\n",
    "df = df.dropna(subset=['date'])\n",
    "df = df.drop(['career'], axis = 1)\n",
    "df = df.drop(['sports','tvsports','exercise','dining',\n",
    "              'museums','art','hiking','gaming',\n",
    "              'clubbing','reading','tv','theater','movies',\n",
    "              'concerts','music','shopping','yoga'], axis = 1)\n",
    "df = df.drop(['expnum'], axis = 1)\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', \n",
    "                                        'intel1_1', 'fun1_1', \n",
    "                                        'amb1_1', 'shar1_1']].sum(axis = 1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "(df.loc[:, ['attr1_1', 'sinc1_1',\n",
    "            'intel1_1', 'fun1_1', \n",
    "            'amb1_1', 'shar1_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1',\n",
    "                                        'intel2_1', 'fun2_1',\n",
    "                                        'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1',\n",
    "           'intel2_1', 'fun2_1',\n",
    "           'amb2_1', 'shar2_1']] = \\\n",
    "(df.loc[:, ['attr2_1', 'sinc2_1',\n",
    "            'intel2_1', 'fun2_1',\n",
    "            'amb2_1', 'shar2_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "df = df.drop(['temp_totalsum'], axis = 1)\n",
    "df = df.dropna()\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    \n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "    df = df.drop(feat, axis=1)\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset = ['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis = 1)\\\n",
    "                                 .dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset = ['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr', 'samerace'], axis = 1)\\\n",
    "                                   .dropna()\n",
    "        \n",
    "df_female.columns = df_female.columns + '_f'\n",
    "df = df_male.join(df_female)\n",
    "df = df.fillna(value = 0)\n",
    "\n",
    "X = np.array(df.drop(['match'], axis = 1))\n",
    "y = np.array(df['match'])\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности. \n",
    "Постройте графики зависимости точности на валидации от глубины дерева, от минимального числа объектов для сплита. \n",
    "Какой максимальной точности удалось достигнуть?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 1, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.8501030592731321\n",
      "\n",
      "min_samples_split = 5, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.8501000214168865\n",
      "\n",
      "min_samples_split = 10, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.8500947051684568\n",
      "\n",
      "min_samples_split = 15, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.850089388920027\n",
      "\n",
      "min_samples_split = 20, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.8501114133778076\n",
      "\n",
      "min_samples_split = 1, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.8500924267762726\n",
      "\n",
      "min_samples_split = 5, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.8501053376653163\n",
      "\n",
      "min_samples_split = 10, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.8500931862403339\n",
      "\n",
      "min_samples_split = 15, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.8501053376653163\n",
      "\n",
      "min_samples_split = 20, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.8500985024887636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danroor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 1, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.850096983560641\n",
      "\n",
      "min_samples_split = 5, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8385280675133172\n",
      "\n",
      "min_samples_split = 10, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8395495466759018\n",
      "\n",
      "min_samples_split = 15, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8501007808809479\n",
      "\n",
      "min_samples_split = 20, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8500947051684568\n",
      "\n",
      "min_samples_split = 1, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.8324933660814237\n",
      "\n",
      "min_samples_split = 5, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.8380306185530993\n",
      "\n",
      "min_samples_split = 10, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.844561250017088\n",
      "\n",
      "min_samples_split = 15, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.8440713956974841\n",
      "\n",
      "min_samples_split = 20, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.8455827291796725\n",
      "\n",
      "min_samples_split = 1, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8259513426565142\n",
      "\n",
      "min_samples_split = 5, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8284689660200589\n",
      "\n",
      "min_samples_split = 10, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8299795400381859\n",
      "\n",
      "min_samples_split = 15, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8415469371573868\n",
      "\n",
      "min_samples_split = 20, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8415385830527115\n",
      "\n",
      "min_samples_split = 1, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.8350071921246615\n",
      "\n",
      "min_samples_split = 5, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.8400386415314441\n",
      "\n",
      "min_samples_split = 10, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.8289770474771364\n",
      "\n",
      "min_samples_split = 15, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.8355069194770635\n",
      "\n",
      "min_samples_split = 20, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.8430651058161277\n",
      "\n",
      "min_samples_split = 1, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.850099261952825\n",
      "\n",
      "min_samples_split = 5, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.8501022998090707\n",
      "\n",
      "min_samples_split = 10, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.8500924267762726\n",
      "\n",
      "min_samples_split = 15, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.850096983560641\n",
      "\n",
      "min_samples_split = 20, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.8501053376653163\n",
      "\n",
      "min_samples_split = 1, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.85008559159972\n",
      "\n",
      "min_samples_split = 5, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.8500924267762726\n",
      "\n",
      "min_samples_split = 10, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.8501000214168865\n",
      "\n",
      "min_samples_split = 15, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.8501030592731321\n",
      "\n",
      "min_samples_split = 20, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.8500977430247024\n",
      "\n",
      "min_samples_split = 1, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8496033319207301\n",
      "\n",
      "min_samples_split = 5, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8440630415928089\n",
      "\n",
      "min_samples_split = 10, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8430628274239435\n",
      "\n",
      "min_samples_split = 15, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8485856500784527\n",
      "\n",
      "min_samples_split = 20, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8501076160575005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danroor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/danroor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:43: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 1, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8345036674519525\n",
      "\n",
      "min_samples_split = 5, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8299802995022473\n",
      "\n",
      "min_samples_split = 10, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8420474239738501\n",
      "\n",
      "min_samples_split = 15, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8355236276864142\n",
      "\n",
      "min_samples_split = 20, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8420671700394465\n",
      "\n",
      "min_samples_split = 1, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8360104441497724\n",
      "\n",
      "min_samples_split = 5, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8264571457214073\n",
      "\n",
      "min_samples_split = 10, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8470705192759573\n",
      "\n",
      "min_samples_split = 15, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8410540449815374\n",
      "\n",
      "min_samples_split = 20, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8299704264694491\n",
      "\n",
      "min_samples_split = 1, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.8400492740283036\n",
      "\n",
      "min_samples_split = 5, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.837516461383531\n",
      "\n",
      "min_samples_split = 10, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.841049488197169\n",
      "\n",
      "min_samples_split = 15, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.8319860440884077\n",
      "\n",
      "min_samples_split = 20, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.8400363631392599\n",
      "\n",
      "min_samples_split = 1, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.8500962240965796\n",
      "\n",
      "min_samples_split = 5, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.8501053376653163\n",
      "\n",
      "min_samples_split = 10, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.8501068565934391\n",
      "\n",
      "min_samples_split = 15, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.850096983560641\n",
      "\n",
      "min_samples_split = 20, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.8501060971293777\n",
      "\n",
      "min_samples_split = 1, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.8501022998090707\n",
      "\n",
      "min_samples_split = 5, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.8500954646325182\n",
      "\n",
      "min_samples_split = 10, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.850099261952825\n",
      "\n",
      "min_samples_split = 15, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.8501022998090709\n",
      "\n",
      "min_samples_split = 20, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.8500909078481498\n",
      "\n",
      "min_samples_split = 1, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.8501076160575005\n",
      "\n",
      "min_samples_split = 5, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.8500992619528253\n",
      "\n",
      "min_samples_split = 10, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.8501068565934391\n",
      "\n",
      "min_samples_split = 15, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.8460794186758287\n",
      "\n",
      "min_samples_split = 20, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.8500992619528253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danroor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 1, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.8325002012579762\n",
      "\n",
      "min_samples_split = 5, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.8269659866425462\n",
      "\n",
      "min_samples_split = 10, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.8395381547149806\n",
      "\n",
      "min_samples_split = 15, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.8395373952509194\n",
      "\n",
      "min_samples_split = 20, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.8480851632619893\n",
      "\n",
      "min_samples_split = 1, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.8184166997033534\n",
      "\n",
      "min_samples_split = 5, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.8239326871813099\n",
      "\n",
      "min_samples_split = 10, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.8219322588435792\n",
      "\n",
      "min_samples_split = 15, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.8410479692690463\n",
      "\n",
      "min_samples_split = 20, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.842556264894989\n",
      "\n",
      "min_samples_split = 1, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.8033253893392511\n",
      "\n",
      "min_samples_split = 5, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.8123819982714598\n",
      "\n",
      "min_samples_split = 10, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.8289694528365222\n",
      "\n",
      "min_samples_split = 15, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.8380290996249765\n",
      "\n",
      "min_samples_split = 20, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.840040160459567\n",
      "\n",
      "{'min_samples_split': 20, 'max_depth': 2, 'criterion': 'gini'}\n",
      "0.8501114133778076\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 3, shuffle = True)\n",
    "\n",
    "min_samples_range = [1, 5, 10, 15, 20]\n",
    "depth_range = [2, 4, 5, 8, 10, 15]\n",
    "crit_range = ['gini', 'entropy', 'misclass']\n",
    "\n",
    "plot_dict = {'gini' : [ [i for i in range(21)] for j in range(16) ],\n",
    "             'entropy' : [ [i for i in range(21)] for j in range(16) ],\n",
    "             'misclass' : [ [i for i in range(21)] for j in range(16) ]}\n",
    "\n",
    "best_model = {}\n",
    "max_score = 0.0\n",
    "\n",
    "for crit in crit_range:\n",
    "    for depth in depth_range:\n",
    "        for min_samples in min_samples_range:\n",
    "            clf = MyDecisionTreeClassifier(min_samples_split = min_samples, max_depth = depth, criterion = crit)\n",
    "            ind = kf.split(X)\n",
    "            scores = []\n",
    "            for train_ind, test_ind in ind:\n",
    "                clf.fit(X[train_ind], y[train_ind])\n",
    "                scores.append(accuracy_score(y[test_ind], clf.predict(X[test_ind])))\n",
    "            score = np.mean(np.array(scores))\n",
    "            \n",
    "            \n",
    "            if score > max_score:\n",
    "                best_model = {'min_samples_split' : min_samples, 'max_depth' : depth, 'criterion' : crit}\n",
    "                max_score = score\n",
    "                \n",
    "            print('''min_samples_split = {}, max_depth =  {}, criterion =  {}\\nf1_score = {}\\n'''\\\n",
    "                                        .format(min_samples, depth, crit, score))\n",
    "            \n",
    "            plot_dict[crit][depth][min_samples] = score\n",
    "            \n",
    "print(best_model)\n",
    "print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = plot_dict[best_model['criterion']] #matrix 16 depths x 21 min_sample_splits\n",
    "\n",
    "scores_from_min_sample = [scores[best_model['max_depth']][min_samples] for min_samples in min_samples_range]\n",
    "scores_from_max_depth = [scores[max_depth][best_model['min_samples_split']] for max_depth in depth_range]\n",
    "\n",
    "l, = plt.plot(min_samples_range, scores_from_min_sample)\n",
    "\n",
    "plt.xlim(0, 25)\n",
    "plt.ylim(0.85, 0.8502)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l, = plt.plot(depth_range, scores_from_max_depth)\n",
    "plt.xlim(0, 20)\n",
    "plt.ylim(0.84, 0.86)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Находим самые важные признаки (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 123)\n",
    "\n",
    "samp = best_model['min_samples_split']\n",
    "depth = best_model['max_depth']\n",
    "crit = best_model['criterion']\n",
    "\n",
    "mytree = MyDecisionTreeClassifier(min_samples_split = samp, max_depth = depth, criterion = crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842964824120603\n"
     ]
    }
   ],
   "source": [
    "mytree.fit(X_train, y_train)\n",
    "y_pred = mytree.predict(X_test)\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = mytree.get_feature_importance()\n",
    "sorted_indices = np.argsort(-feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2854698  0.25375491 0.21571314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(feat_imp[sorted_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun3_1' 'imprelig' 'fun2_1' 'iid' 'date_f' 'goal_f' 'income_f'\n",
      " 'zipcode_f' 'imprelig_f' 'imprace_f']\n"
     ]
    }
   ],
   "source": [
    "ddf = df.drop(['match'], axis = 1)\n",
    "features = ddf.columns.values\n",
    "imp_feat = features[sorted_indices[:10]]\n",
    "print(imp_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
